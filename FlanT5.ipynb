{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_uvnIwBeCWd",
        "outputId": "dce02617-c3a3-4b4f-8e18-f0904e290bd8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWK_3XRhgHTU"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "g8tPhaXevxnX",
        "outputId": "56355ad0-845a-4657-d93e-e48bd5e0231d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZfrotksxT84"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/drive/My Drive/data_cs334/rewritten_texts_csv.csv', encoding='ISO-8859-1')\n",
        "\n",
        "file_path_score = '/content/drive/My Drive/data_cs334/Gemma_Rewriting_Score_Descriptors.txt'\n",
        "\n",
        "with open(file_path_score, 'r') as file:\n",
        "    score = file.read()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LXqkllOfH98"
      },
      "outputs": [],
      "source": [
        "def construct_input(row, scores):\n",
        "    prompt = scores + '\\n\\n'\n",
        "    #prompt += 'Here are a few grading examples: \\n\\n'\n",
        "    #prompt += examples + '\\n\\n'\n",
        "    prompt += 'Original text:\\n\\n'\n",
        "    prompt += row['original_text'] + '\\n\\n'\n",
        "    prompt += 'Prompt to rewrite the original text:\\n\\n'\n",
        "    prompt += row['prompt'] + '\\n\\n'\n",
        "    prompt += 'Rewritten text:\\n\\n'\n",
        "    prompt += row['rewritten_text'] + '\\n\\n'\n",
        "    prompt += 'Score: \\n\\n'\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "747d66c702464fbaa6af120224ba237e",
            "a22ec819d13348fb84e8ea8562945c98",
            "3f15333501794592a27ac720f4a4b52e",
            "3149b97447e845dfba47682cf870399f",
            "284414ea00724b22a51e963523f09515",
            "d1216c5fb4844dcfbe1cb31986b44a27",
            "fe06a7c41a074831b83a0e32faad623c"
          ]
        },
        "id": "FTJMyJ4owRjs",
        "outputId": "0ff6a4b2-216f-4b7c-d025-7db0f699ad9c"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import csv\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
        "tokenizer.model_max_length = 4096\n",
        "\n",
        "with open('/content/drive/My Drive/data_cs334/Gemma_Rewriting_Score_Descriptors.txt', 'r') as file:\n",
        "    score_descriptors = file.read()\n",
        "\n",
        "start = 0\n",
        "end = 10000\n",
        "\n",
        "\n",
        "with open('/content/drive/My Drive/data_cs334/evaluation_results.csv', mode='a', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    #writer.writerow([\"Prompt\", \"Original Text\", \"Rewritten Text\", \"Score\"])\n",
        "\n",
        "    for index in range(start, end):\n",
        "        row = data.iloc[index]\n",
        "        input_text = construct_input(row, score_descriptors)\n",
        "        inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "        outputs = model.generate(**inputs, max_new_tokens=50)\n",
        "        score = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "        writer.writerow([row['prompt'], row['original_text'], row['rewritten_text'], score])\n",
        "        print('Completed index: ' + str(index) + '\\n')\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
